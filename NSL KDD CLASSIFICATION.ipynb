{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "#STEP 1: LOAD DATA\n",
    "dataset_root = 'nsl-kdd'\n",
    "#train_x.describe()\n",
    "header_names = ['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'attack_type', 'success_pred']\n",
    "\n",
    "category = defaultdict(list)\n",
    "category['benign'].append('normal')\n",
    "\n",
    "with open('training_attack_types.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        attack, cat = line.strip().split(' ')\n",
    "        category[cat].append(attack)\n",
    "#print(category)\n",
    "\n",
    "attack_mapping = dict((v,k) for k in category for v in category[k])\n",
    "#print(attack_mapping)\n",
    "\n",
    "#load train/test files\n",
    "train_file = os.path.join(dataset_root, 'KDDTrain+.txt')\n",
    "test_file = os.path.join(dataset_root, 'KDDTest+.txt')\n",
    "\n",
    "#READ TRAINING DATA\n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(train_file, names=header_names)\n",
    "train_df['attack_category'] = train_df['attack_type'] \\\n",
    "    .map(lambda x: attack_mapping[x])\n",
    "train_df.drop(['success_pred'], axis=1, inplace=True)\n",
    "\n",
    "test_df = pd.read_csv(train_file, names=header_names)\n",
    "test_df['attack_category'] = test_df['attack_type'] \\\n",
    ".map(lambda x: attack_mapping[x])\n",
    "test_df.drop(['success_pred'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###STEP 2: UNDERSTAND DATA (visualize)\n",
    "import matplotlib.pyplot as plt\n",
    "train_attack_types = train_df['attack_type'].value_counts()\n",
    "train_attack_cats = train_df['attack_category'].value_counts()\n",
    "train_attack_types.plot(kind='barh')\n",
    "plt.show()\n",
    "train_attack_cats.plot(kind='barh')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#DATA PREPARATION\n",
    "train_Y = train_df['attack_category']\n",
    "train_x_raw = train_df.drop(['attack_category','attack_type'], axis=1)\n",
    "test_Y = test_df['attack_category']\n",
    "test_x_raw = test_df.drop(['attack_category','attack_type'], axis=1)\n",
    "feature_names = defaultdict(list)\n",
    "with open('kddcup.names.txt', 'r') as f:\n",
    "    for line in f.readlines()[1:]:\n",
    "        name, nature = line.strip()[:-1].split(': ')\n",
    "        feature_names[nature].append(name)\n",
    "print(feature_names)\n",
    "\n",
    "\n",
    "\n",
    "#FEATURE ENGINEERING\n",
    "# Concatenate DataFrames\n",
    "combined_df_raw = pd.concat([train_x_raw, test_x_raw])\n",
    "# Keep track of continuous, binary, and nominal features\n",
    "continuous_features = feature_names['continuous']\n",
    "continuous_features.remove('root_shell')\t\t\t#Dataset has an error\n",
    "binary_features = ['land','logged_in','root_shell', 'su_attempted','is_host_login', 'is_guest_login']\n",
    "nominal_features = list(set(feature_names['symbolic']) - set(binary_features))\n",
    "# Generate dummy variables\n",
    "combined_df = pd.get_dummies(combined_df_raw, \\\n",
    "columns=feature_names['symbolic'], \\\n",
    "drop_first=True)\n",
    "# Separate into training and test sets again\n",
    "train_x = combined_df[:len(train_x_raw)]\n",
    "test_x = combined_df[len(train_x_raw):]\n",
    "# Keep track of dummy variables\n",
    "dummy_variables = list(set(train_x)-set(combined_df_raw))\n",
    "#train_x.describe()\n",
    "\n",
    "\n",
    "#NORMALIZATION (src_bytes > num_failed_logs by 10^7)\n",
    "#what is normalization? show pictures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Fit StandardScaler to the training data\n",
    "standard_scaler = StandardScaler().fit(train_x[continuous_features])\n",
    "# Standardize training data\n",
    "train_x[continuous_features] = \\\n",
    "\tstandard_scaler.transform(train_x[continuous_features])\n",
    "# Standardize test data with scaler fitted to training data\n",
    "test_x[continuous_features] = \\\n",
    "\tstandard_scaler.transform(test_x[continuous_features])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#STEP 5: CLASSIFICATION\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, zero_one_loss\n",
    "classifier = DecisionTreeClassifier(random_state=0)\n",
    "classifier.fit(train_x, train_Y)\n",
    "pred_y = classifier.predict(test_x)\n",
    "results = confusion_matrix(test_Y, pred_y)\n",
    "error = zero_one_loss(test_Y, pred_y)\n",
    "#STEP 6: Check results\n",
    "print(results)\n",
    "print(error)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
